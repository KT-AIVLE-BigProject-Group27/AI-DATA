import os
import sys
import re
import unicodedata
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from sklearn.model_selection import train_test_split
from transformers import (
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer,
    EarlyStoppingCallback,
    AutoTokenizer
)
import evaluate
from datasets import Dataset
from functools import partial

# ê²½ë¡œ ì„¤ì •: summarization_models ëª¨ë“ˆ(ëª¨ë¸ ìƒì„± í•¨ìˆ˜ í¬í•¨)
sys.path.append(os.path.abspath("./AI"))
from summarization_models import get_kobart_model

# device ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


##############################################
# (0) í† í°í™” ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ (ì…ë ¥ ë° ìš”ì•½)
##############################################
def preprocess_function(examples, tokenizer, max_input_length=1024, max_target_length=256):
    """
    examples: dict, keys "text" and "summary"
    tokenizer: Hugging Face í† í¬ë‚˜ì´ì €
    """
    # ì…ë ¥ í…ìŠ¤íŠ¸ í† í°í™”
    model_inputs = tokenizer(examples["text"],
                             max_length=max_input_length,
                             truncation=True,
                             padding="max_length")
    # ìš”ì•½ í…ìŠ¤íŠ¸ í† í°í™”
    labels = tokenizer(examples["summary"],
                       max_length=max_target_length,
                       truncation=True,
                       padding="max_length")
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs


##############################################
# (1) í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ (ROUGE ê¸°ë°˜)
##############################################
def compute_metrics_fn(eval_pred, tokenizer):
    """
    eval_pred: (predictions, labels)
    tokenizer: Hugging Face í† í¬ë‚˜ì´ì €
    """
    rouge = evaluate.load("rouge")
    predictions, labels = eval_pred

    # ì˜ˆì¸¡ê°’ ë””ì½”ë”©
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # -100ì„ tokenizerì˜ pad_token_idë¡œ ëŒ€ì²´í•œ í›„ ë””ì½”ë”©
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    result = rouge.compute(predictions=decoded_preds,
                           references=decoded_labels,
                           use_stemmer=True)
    # ê²°ê³¼ê°’ ìŠ¤ì¼€ì¼ ì¡°ì •
    result = {key: value * 100 for key, value in result.items()}
    return result


##############################################
# (2) ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
##############################################
# ê¸°ë³¸ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
base_save_path = os.path.join("E:/Model/ver2", "summarization_comparison")
os.makedirs(base_save_path, exist_ok=True)

# CSV ë°ì´í„° ë¡œë“œ (ì»¬ëŸ¼: "input", "summary")
directory_path = r'./Data_Analysis/Data_ver2/summary_data/'
csv_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]
dfs = [pd.read_csv(os.path.join(directory_path, file)) for file in csv_files]
merged_df = pd.concat(dfs, ignore_index=True)

# article ì»¬ëŸ¼ ìƒì„± (ì˜ˆì‹œ: 'input'ì˜ ì•ë¶€ë¶„ ê¸°ì¤€)
merged_df['article'] = merged_df['input'].apply(lambda x: x.split('[')[0].strip())


# í…ìŠ¤íŠ¸ í´ë¦°ì§• í•¨ìˆ˜: ë¶ˆí•„ìš”í•œ ë”°ì˜´í‘œ ì œê±° ë° ê³µë°± ì •ë¦¬
def clean_whitespace(text):
    text = text.replace('â€œ', '').replace('â€', '').replace("'", '').replace('"', '')
    return re.sub(r'\s{2,}', ' ', text.strip())


merged_df['input'] = merged_df['input'].apply(clean_whitespace)
merged_df['summary'] = merged_df['summary'].apply(clean_whitespace)

# í† í° ê¸¸ì´ ì¸¡ì •ì„ ìœ„í•´ ì„ì‹œë¡œ í† í¬ë‚˜ì´ì € ìƒì„± (ëª¨ë¸ ë¡œë“œ ì „)
# â€» get_kobart_model()ë¡œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ë©´ ë˜ì§€ë§Œ, í† í° ê¸¸ì´ í™•ì¸ì„ ìœ„í•´ ì„ì‹œ í† í¬ë‚˜ì´ì € ì‚¬ìš©
temp_tokenizer = AutoTokenizer.from_pretrained("gogamza/kobart-summarization")
merged_df["input_token_length"] = merged_df["input"].apply(lambda x: len(temp_tokenizer.encode(x)))
merged_df["summary_token_length"] = merged_df["summary"].apply(lambda x: len(temp_tokenizer.encode(x)))

max_input_token_length = merged_df["input_token_length"].max()
max_summary_token_length = merged_df["summary_token_length"].max()
print(f"ğŸ“Œ ìµœëŒ€ input í† í° ê¸¸ì´: {max_input_token_length}")
print(f"ğŸ“Œ ìµœëŒ€ summary í† í° ê¸¸ì´: {max_summary_token_length}")

# (ì˜µì…˜) 1024 í† í° ì´ìƒì¸ ë°ì´í„° í™•ì¸
long_token_texts = merged_df[merged_df["input_token_length"] > 1024]
print(long_token_texts)


# ì¶”ê°€ í…ìŠ¤íŠ¸ ì •ì œ: ìœ ë‹ˆì½”ë“œ ì •ê·œí™” ë° íŠ¹ìˆ˜ ë¬¸ì/íŠ¹ìˆ˜ ìˆ«ì ë³€í™˜
def clean_text(text):
    text = unicodedata.normalize('NFKC', text)
    text = re.sub(r'[^\uAC00-\uD7A3a-zA-Z0-9\s]', '', text)
    return text


def convert_special_numbers(text):
    special_numbers = {
        'â‘ ': '(1)', 'â‘¡': '(2)', 'â‘¢': '(3)', 'â‘£': '(4)', 'â‘¤': '(5)',
        'â‘¥': '(6)', 'â‘¦': '(7)', 'â‘§': '(8)', 'â‘¨': '(9)', 'â‘©': '(10)'
    }
    for k, v in special_numbers.items():
        text = text.replace(k, v)
    return text


merged_df['input'] = merged_df['input'].apply(lambda x: convert_special_numbers(clean_text(x)))
merged_df['summary'] = merged_df['summary'].apply(clean_text)

# Train/Test Split (ì˜ˆ: 80% train, 20% validation), stratify ê¸°ì¤€ì€ 'article'
X_train, X_val, y_train, y_val = train_test_split(
    merged_df['input'],
    merged_df['summary'],
    test_size=0.2,
    random_state=42,
    stratify=merged_df['article']
)
train_data = pd.DataFrame({'text': X_train, 'summary': y_train})
val_data = pd.DataFrame({'text': X_val, 'summary': y_val})
print(f'X_train: {len(X_train)}, X_val: {len(X_val)}')

##############################################
# (3) í•™ìŠµ ë° í‰ê°€ ë£¨í”„
##############################################
# ëª¨ë¸ ë¦¬ìŠ¤íŠ¸: (ëª¨ë¸ëª…, ìƒì„± í•¨ìˆ˜)
models_info = [
    ("kobart", get_kobart_model),
]

# í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
num_train_epochs = 100
per_device_train_batch_size = 8
per_device_eval_batch_size = 8
learning_rate = 3e-5

# ê° ëª¨ë¸ì— ëŒ€í•´ í•™ìŠµ ë° í‰ê°€ ìˆ˜í–‰
for model_label, get_model_fn in models_info:
    print("\n" + "=" * 50)
    print(f"ëª¨ë¸: {model_label} í•™ìŠµ ì‹œì‘")

    # 1. ëª¨ë¸ ì €ì¥ ê²½ë¡œ ìƒì„±
    cur_save_path = os.path.join(base_save_path, model_label)
    os.makedirs(cur_save_path, exist_ok=True)

    # 2. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ ë° device í• ë‹¹
    model, tokenizer = get_model_fn()
    model.to(device)

    # 3. Hugging Face Datasetìœ¼ë¡œ ë³€í™˜
    train_dataset = Dataset.from_pandas(train_data)
    val_dataset = Dataset.from_pandas(val_data)

    # 4. ë°ì´í„° í† í°í™” (í•¨ìˆ˜ì— tokenizerë¥¼ ì¸ìë¡œ ì „ë‹¬)
    tokenized_train_dataset = train_dataset.map(
        lambda examples: preprocess_function(examples, tokenizer),
        batched=True
    ).with_format("torch")
    tokenized_val_dataset = val_dataset.map(
        lambda examples: preprocess_function(examples, tokenizer),
        batched=True
    ).with_format("torch")

    # 5. compute_metrics í•¨ìˆ˜ì— tokenizer ì „ë‹¬ (partial ì‚¬ìš©)
    compute_metrics = partial(compute_metrics_fn, tokenizer=tokenizer)

    # 6. TrainingArguments ì„¤ì •
    training_args = Seq2SeqTrainingArguments(
        output_dir=os.path.join(cur_save_path, "results"),
        evaluation_strategy="epoch",
        save_strategy="epoch",
        save_total_limit=3,
        learning_rate=learning_rate,
        load_best_model_at_end=True,
        metric_for_best_model="rouge1",  # ROUGE ê¸°ì¤€ ìµœì  ëª¨ë¸ ì„ íƒ
        greater_is_better=True,
        per_device_train_batch_size=per_device_train_batch_size,
        per_device_eval_batch_size=per_device_eval_batch_size,
        weight_decay=0.01,
        num_train_epochs=num_train_epochs,
        predict_with_generate=True,
        fp16=True if device.type == "cuda" else False,
        logging_dir=os.path.join(cur_save_path, "logs"),
        remove_unused_columns=False,
        gradient_accumulation_steps=2,
    )

    # 7. Seq2SeqTrainer ì´ˆê¸°í™”
    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_train_dataset,
        eval_dataset=tokenized_val_dataset,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics,
    )

    # 8. (ì˜µì…˜) ë°ì´í„°ì…‹ì˜ í¬ë§·ì„ torchë¡œ ëª…ì‹œ (ì´ë¯¸ with_format("torch")ë¥¼ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ ìƒëµ ê°€ëŠ¥)
    tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
    tokenized_val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])

    # 9. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    trainer.train()

    # 10. í•™ìŠµ ë¡œê·¸ ì €ì¥ (CSV ë° Loss Curve ê·¸ë¦¼)
    loss_history = pd.DataFrame(trainer.state.log_history)
    loss_history.to_csv(os.path.join(cur_save_path, "loss_history.csv"), index=False)

    plt.figure(figsize=(6, 4))
    train_losses = [entry["loss"] for entry in trainer.state.log_history if "loss" in entry]
    eval_losses = [entry["eval_loss"] for entry in trainer.state.log_history if "eval_loss" in entry]
    plt.plot(train_losses, label="Train Loss", marker="o")
    plt.plot(eval_losses, label="Validation Loss", marker="o")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title(f"{model_label} Loss Curve")
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(cur_save_path, "loss_curve.png"))
    plt.close()

    # 11. ëª¨ë¸ í‰ê°€ ì‹¤í–‰
    eval_results = trainer.evaluate()
    print(f"[{model_label}] í‰ê°€ ê²°ê³¼:")
    print(eval_results)

    # 12. í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
    model_save_path = os.path.join(cur_save_path, f"{model_label}_summarization")
    os.makedirs(model_save_path, exist_ok=True)
    model.save_pretrained(model_save_path)
    tokenizer.save_pretrained(model_save_path)
    print(f"âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥ ì™„ë£Œ: {model_save_path}")

##############################################
# (4) ì €ì¥ëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë° ì˜ˆì¸¡ ìˆ˜í–‰, í‰ê°€ ê²°ê³¼ ì €ì¥
##############################################
results_summary = []  # ëª¨ë¸ë³„ í‰ê°€ ì§€í‘œ ì €ì¥
for model_label, get_model_fn in models_info:
    print("\n" + "=" * 50)
    print(f"ëª¨ë¸: {model_label} í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
    cur_save_path = os.path.join(base_save_path, model_label)
    model_save_path = os.path.join(cur_save_path, f"{model_label}_summarization")

    # ì €ì¥ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
    model, tokenizer = get_model_fn()
    model = model.__class__.from_pretrained(model_save_path)
    tokenizer = type(tokenizer).from_pretrained(model_save_path)
    model.to(device)

    # Datasetìœ¼ë¡œ ë³€í™˜ í›„ í† í°í™”
    train_dataset = Dataset.from_pandas(train_data)
    val_dataset = Dataset.from_pandas(val_data)
    tokenized_val = val_dataset.map(
        lambda examples: preprocess_function(examples, tokenizer),
        batched=True,
        remove_columns=val_dataset.column_names
    )

    # Trainer í‰ê°€ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ TrainingArguments ì„¤ì •
    eval_training_args = Seq2SeqTrainingArguments(
        output_dir="./dummy_output",
        per_device_eval_batch_size=4,
        predict_with_generate=True,
        evaluation_strategy="no",
        remove_unused_columns=False
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=eval_training_args,
        eval_dataset=tokenized_val,
        tokenizer=tokenizer,
    )

    # í‰ê°€ ì‹¤í–‰
    eval_results = trainer.evaluate()
    print(f"[{model_label}] í‰ê°€ ê²°ê³¼:")
    print(eval_results)

    # ê²°ê³¼ ì €ì¥: eval_loss ë° (ìˆë‹¤ë©´) ROUGE-L ì ìˆ˜
    result_entry = {
        "Model": model_label,
        "Eval_Loss": eval_results.get("eval_loss", np.nan),
        "RougeL": eval_results.get("eval_rougeL", np.nan)
    }
    results_summary.append(result_entry)

    # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê²°ê³¼ CSV ì €ì¥
    predictions = trainer.predict(tokenized_val)
    decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)
    decoded_labels = tokenizer.batch_decode(predictions.label_ids, skip_special_tokens=True)
    original_inputs = val_data["text"].tolist()
    results_df = pd.DataFrame({
        "Input": original_inputs,
        "Predicted_Summary": decoded_preds,
        "Ground_Truth_Summary": decoded_labels
    })
    results_csv_path = os.path.join(cur_save_path, f"{model_label}_summarization_results.csv")
    results_df.to_csv(results_csv_path, index=False, encoding="utf-8-sig")
    print(f"âœ… ëª¨ë¸ ì…ë ¥/ì¶œë ¥ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_csv_path}")

# ëª¨ë¸ë³„ í‰ê°€ ì§€í‘œ ìš”ì•½ ë° ì‹œê°í™”
results_df = pd.DataFrame(results_summary)
print("\nì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
print(results_df)

# í‰ê°€ ì§€í‘œë³„ bar chart ìƒì„±
metrics = ["Eval_Loss", "RougeL"]
num_metrics = len(metrics)
fig, axs = plt.subplots(1, num_metrics, figsize=(5 * num_metrics, 5))
if num_metrics == 1:
    axs = [axs]
for i, metric in enumerate(metrics):
    axs[i].bar(results_df["Model"], results_df[metric], color="skyblue")
    axs[i].set_title(metric)
    axs[i].set_ylim([0, results_df[metric].max() * 1.2])
    for j, value in enumerate(results_df[metric]):
        axs[i].text(j, value + 0.02 * results_df[metric].max(), f"{value:.2f}",
                    ha="center", va="bottom", fontsize=10)
plt.suptitle("ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ", fontsize=16)
plt.tight_layout()
comparison_plot_file = os.path.join(base_save_path, "model_comparison.png")
plt.savefig(comparison_plot_file)
plt.show()
