"""
1. í•™ìŠµ ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°
ë¶ˆê³µì • ì¡°í•­ê³¼ ë…ì†Œ ì¡°í•­ì€ ëŒ€ë¶€ë¶„ ë¶ˆê· í˜• ë°ì´í„°ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ (ì¼ë°˜ ì¡°í•­ì´ ë” ë§ì„ ìˆ˜ë„ ìˆìŒ)
ë¶ˆê· í˜• ë°ì´í„° ë¬¸ì œë¥¼ í•´ê²°í•˜ë©´ ëª¨ë¸ì´ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹˜ì§€ ì•Šê³  ì¼ë°˜í™” ì„±ëŠ¥ì´ ì¢‹ì•„ì§
â¡ í•´ê²° ë°©ë²•:
âœ” Focal Loss ì ìš©
âœ” Weighted Random Samplerë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë°ì´í„°ì˜ ë¶ˆê· í˜•ì„ ì™„í™”

âœ” Focal Loss ì ìš© (CrossEntropyLoss ëŒ€ì‹  ì‚¬ìš©)

class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.bce_loss = nn.BCELoss()

    def forward(self, inputs, targets):
        BCE_loss = self.bce_loss(inputs, targets)
        pt = torch.exp(-BCE_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss
        return focal_loss.mean()

â¡ criterion = FocalLoss() ë¡œ ë³€ê²½í•˜ì—¬ í•™ìŠµ ì§„í–‰
âœ” Weighted Random Sampler ì ìš© (ë°ì´í„° ë¹„ìœ¨ ë§ì¶”ê¸°)
from torch.utils.data.sampler import WeightedRandomSampler

# í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ê°œìˆ˜ ê³„ì‚°
class_sample_counts = [sum(y_train), len(y_train) - sum(y_train)]
weights = 1. / torch.tensor(class_sample_counts, dtype=torch.float)
sample_weights = weights[y_train_tensor.squeeze().long()]

sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)
train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)
â¡ ë°ì´í„° ê· í˜•ì„ ë§ì¶”ë©´ì„œ í•™ìŠµ ì§„í–‰ ê°€ëŠ¥

2. í˜¼ë™ í–‰ë ¬(Confusion Matrix) ë¶„ì„
í•™ìŠµ í›„ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ë ¤ë©´ í˜¼ë™ í–‰ë ¬(Confusion Matrix) ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¤‘ìš”
ë‹¨ìˆœíˆ loss ê°’ë§Œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì˜¤ë¶„ë¥˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì„ ê°œì„  ê°€ëŠ¥
â¡ í•´ê²° ë°©ë²•:
âœ” sklearn.metrics.confusion_matrixë¥¼ í™œìš©í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
âœ” classification_report ë¡œ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ í™•ì¸
from sklearn.metrics import confusion_matrix, classification_report

def evaluate_model(model, data_loader):
    model.eval()
    y_preds, y_trues = [], []

    with torch.no_grad():
        for X_batch, mask_batch, y_batch in data_loader:
            X_batch, mask_batch, y_batch = X_batch.to(device), mask_batch.to(device), y_batch.to(device)
            outputs = model(X_batch, mask_batch)
            preds = (outputs >= 0.5).float()  # 0.5 ì´ìƒì´ë©´ 1(ë…ì†Œ ì¡°í•­), ë¯¸ë§Œì´ë©´ 0(ì¼ë°˜ ì¡°í•­)
            y_preds.extend(preds.cpu().numpy())
            y_trues.extend(y_batch.cpu().numpy())

    # âœ… í˜¼ë™ í–‰ë ¬ ì¶œë ¥
    cm = confusion_matrix(y_trues, y_preds)
    print("\nğŸ”¹ Confusion Matrix:")
    print(cm)

    # âœ… ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ì¶œë ¥
    report = classification_report(y_trues, y_preds, target_names=["ì •ìƒ ì¡°í•­", "ë…ì†Œ ì¡°í•­"])
    print("\nğŸ”¹ Classification Report:")
    print(report)

# âœ… í•™ìŠµ ì™„ë£Œ í›„ í‰ê°€ ì‹¤í–‰
evaluate_model(loaded_model, val_loader)


"""